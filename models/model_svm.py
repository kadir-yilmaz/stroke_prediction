"""
Support Vector Machine (SVM) Modeli
===================================
Karar sÄ±nÄ±rÄ± Ã§izerek sÄ±nÄ±flarÄ± ayÄ±ran gÃ¼Ã§lÃ¼ model.

AvantajlarÄ±:
- YÃ¼ksek boyutlu verilerde etkili
- Kernel trick ile doÄŸrusal olmayan sÄ±nÄ±rlar
- Overfitting'e dayanÄ±klÄ±

DezavantajlarÄ±:
- BÃ¼yÃ¼k veri setlerinde yavaÅŸ
- Ã–lÃ§ekleme ÅŸart!
- Probability estimation yavaÅŸ
"""

from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from data_utils import load_data_with_smote, print_results

def train_svm():
    # Veriyi yÃ¼kle
    X_train, X_test, y_train, y_test, feature_names = load_data_with_smote()
    
    # Model oluÅŸtur
    # RBF kernel: DoÄŸrusal olmayan sÄ±nÄ±rlar iÃ§in
    model = SVC(
        kernel='rbf',             # Radial Basis Function
        C=1.0,                    # Regularization (kÃ¼Ã§Ã¼k = daha fazla reg.)
        gamma='scale',            # Kernel katsayÄ±sÄ±
        probability=True,         # predict_proba iÃ§in gerekli
        random_state=42
    )
    
    # Cross-validation (SVM yavaÅŸ olduÄŸu iÃ§in cv=3)
    cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc')
    print(f"\nğŸ”„ 3-Fold Cross-Validation ROC-AUC: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
    
    # EÄŸitim
    print("â³ SVM eÄŸitiliyor (biraz zaman alabilir)...")
    model.fit(X_train, y_train)
    
    # Tahmin
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]
    
    # SonuÃ§larÄ± yazdÄ±r
    results = print_results("SVM (RBF Kernel)", y_test, y_pred, y_prob)
    
    # SVM'de feature importance yok, support vector sayÄ±sÄ±nÄ± gÃ¶sterelim
    print(f"\nğŸ“Š Support Vector SayÄ±sÄ±: {sum(model.n_support_)}")
    print(f"   - Class 0 (SaÄŸlÄ±klÄ±): {model.n_support_[0]}")
    print(f"   - Class 1 (FelÃ§): {model.n_support_[1]}")
    
    return model, results


if __name__ == "__main__":
    model, results = train_svm()
