"""
TÃ¼m modeller iÃ§in paylaÅŸÄ±lan veri yÃ¼kleme ve Ã¶n iÅŸleme fonksiyonlarÄ±.
"""

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# Proje kÃ¶k dizini
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
DEFAULT_FILEPATH = os.path.join(PROJECT_ROOT, "healthcare-dataset-stroke-data.csv")

def load_and_preprocess_data(filepath=None):
    """
    Veriyi yÃ¼kler ve Ã¶n iÅŸleme yapar.
    
    Returns:
        X_train, X_test, y_train, y_test: EÄŸitim ve test verileri
        feature_names: Ã–zellik isimleri
    """
    # 1. Veri YÃ¼kleme
    if filepath is None:
        filepath = DEFAULT_FILEPATH
    df = pd.read_csv(filepath)
    df.drop("id", axis=1, inplace=True)
    
    # 2. BMI eksik deÄŸerlerini doldur
    df["bmi"] = pd.to_numeric(df["bmi"], errors="coerce")
    df["bmi"].fillna(df["bmi"].median(), inplace=True)
    
    # 3. One-Hot Encoding (Label Encoding yerine - daha doÄŸru)
    # Kategorik sÃ¼tunlar sÄ±ralÄ± olmadÄ±ÄŸÄ± iÃ§in One-Hot tercih edilir
    df = pd.get_dummies(df, columns=[
        "gender", "ever_married", "work_type", 
        "Residence_type", "smoking_status"
    ], drop_first=True)
    
    # 4. Ã–zellik ve Hedef AyrÄ±mÄ±
    X = df.drop("stroke", axis=1)
    y = df["stroke"]
    feature_names = X.columns.tolist()
    
    # 5. Train/Test Split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )
    
    # 6. Ã–lÃ§ekleme
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    return X_train_scaled, X_test_scaled, y_train, y_test, feature_names


def load_data_with_smote(filepath=None):
    """
    Veriyi yÃ¼kler, SMOTE ile dengesizliÄŸi giderir.
    
    Dengesiz veri setlerinde azÄ±nlÄ±k sÄ±nÄ±fÄ±nÄ± sentetik olarak Ã§oÄŸaltÄ±r.
    """
    # Ã–nce normal ÅŸekilde yÃ¼kle
    if filepath is None:
        filepath = DEFAULT_FILEPATH
    X_train, X_test, y_train, y_test, feature_names = load_and_preprocess_data(filepath)
    
    # SMOTE uygula (sadece eÄŸitim verisine!)
    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
    
    print(f"SMOTE Ã–ncesi: {sum(y_train==0)} saÄŸlÄ±klÄ±, {sum(y_train==1)} felÃ§")
    print(f"SMOTE SonrasÄ±: {sum(y_train_resampled==0)} saÄŸlÄ±klÄ±, {sum(y_train_resampled==1)} felÃ§")
    
    return X_train_resampled, X_test, y_train_resampled, y_test, feature_names


def print_results(model_name, y_test, y_pred, y_prob=None):
    """
    Model sonuÃ§larÄ±nÄ± gÃ¼zel bir ÅŸekilde yazdÄ±rÄ±r.
    """
    from sklearn.metrics import (
        accuracy_score, roc_auc_score, precision_score, 
        recall_score, f1_score, classification_report
    )
    
    acc = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    
    print(f"\n{'='*50}")
    print(f"ğŸ“Š {model_name} SONUÃ‡LARI")
    print(f"{'='*50}")
    print(f"âœ… Accuracy (DoÄŸruluk)  : %{acc*100:.2f}")
    print(f"ğŸ¯ Precision (Kesinlik) : %{precision*100:.2f}")
    print(f"ğŸ” Recall (Yakalama)    : %{recall*100:.2f}")
    print(f"âš–ï¸  F1-Score            : %{f1*100:.2f}")
    
    if y_prob is not None:
        auc = roc_auc_score(y_test, y_prob)
        print(f"ğŸ“ˆ ROC-AUC             : {auc:.4f}")
    
    print(f"\n{'-'*50}")
    print("ğŸ“‹ DetaylÄ± Rapor:")
    print(classification_report(y_test, y_pred, 
                                target_names=['SaÄŸlÄ±klÄ± (0)', 'FelÃ§ (1)']))
    
    return {
        'model': model_name,
        'accuracy': acc,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'auc': roc_auc_score(y_test, y_prob) if y_prob is not None else None
    }
